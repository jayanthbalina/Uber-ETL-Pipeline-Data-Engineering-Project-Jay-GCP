# Uber Data Analytics | Modern Data Engineering GCP Project

## Project Overview
The goal of this project is to perform data analytics on Uber data using various tools and technologies. This includes leveraging Google Cloud Platform (GCP) services such as GCP Storage, Compute Instances, Mage Data Pipeline Tool, BigQuery, and Looker Studio.

## Technology Used
- **Programming Language**: Python
- **Google Cloud Platform**:
  - **Google Storage**: For storing raw data files.
  - **Compute Instance**: To run Python scripts and process data.
  - **BigQuery**: For analyzing large datasets and performing complex queries.
  - **Looker Studio**: For visualizing data and creating interactive reports.
- **Modern Data Pipeline Tool**: [Mage Data Pipeline Tool](https://www.mage.ai/)

## Dataset Used
The project utilizes the TLC Trip Record Data, which includes:
- **Taxi Trip Records**: Yellow and green taxi trip records.
- **Fields Included**:
  - Pick-up and drop-off dates/times
  - Pick-up and drop-off locations
  - Trip distances
  - Itemized fares
  - Rate types
  - Payment types
  - Driver-reported passenger counts

### Dataset Link
[Uber Data CSV](https://storage.googleapis.com/uber-data-engineering-project-jayanthbalina/uber_data.csv)

## Conclusion
This project aims to provide insights into Uber's operational data, helping stakeholders understand ride patterns, pricing, and demand trends. The integration of various GCP tools ensures a scalable and efficient data processing and analytics pipeline.

## Skills
- **Data Analysis**: Leveraging analytics to derive meaningful insights from data.
- **Data Engineering**: Building robust data pipelines and storage solutions.
- **Cloud Computing**: Utilizing GCP services for data management and analysis.
